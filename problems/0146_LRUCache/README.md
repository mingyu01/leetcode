关于这道问题的详细解析参见：

- [https://labuladong.gitbook.io/algo/shu-ju-jie-gou-xi-lie/lru-suan-fa](https://labuladong.gitbook.io/algo/shu-ju-jie-gou-xi-lie/lru-suan-fa)



根据这道题的要求，如果我们同时还想让 `put` 和 `get` 方法的时间复杂度均为 `O(1)` ，那么 `cache` 这个数据结构应该同时要满足以下三个条件：

- `cache` 中的元素必须要有时序，以区分最近使用的和很长时间没有使用过的数据。这样做的目的是当 `cache` 容量满了以后，我们可以知道要删除的元素是哪一个元素，从而为新来的元素腾出位置。
- 我们要能够快速地在 `cache` 中找到某个 `key` ，如果这个 `key` 存在，返回它对应的 `value` 值；如果不存在，返回 `-1` 。
- 每次访问 `cache` 中的某个 `key` 时，需要将这个元素变为最近使用的。也就是说，`cache` 要支持在任意位置快速插入和删除。

综合以上三个特点，什么样的数据结构能同时满足这三个需求呢？哈希表查找快，但是它里面的数据没有固定顺序，不能体现出时序；链表有顺序之分，插入删除快，但是查找慢。所以这两个结合一下，就形成了一种新的数据结构：哈希链表（Linked-HashMap）—— 哈希表和双向链表的结合体。

借助这一结构，我们可以这样来分析 LRU 这个问题：

- 如果我们每次默认从链表尾部添加元素，那么显然越靠近尾部的元素就是最近使用的，越靠近头部的元素就是越久未使用的。
- 对于某一个 `key` ，我们可以通过哈希表快速定位到链表中的节点，从而取得对应的 `value` 值。
- 链表支持在任意位置快速插入和删除，只需要改改指针就行。当我们使用 `get` 方法时，为了把 `get` 到的元素变成最近使用的元素，我们要先在链表中将其删除，然后再把它添加到链表的尾部。我们在使用 `put` 方法时，如果哈希表中已经有这个 `key` 值了，那我们就先把这个 `key` 值给删掉，然后再链表的尾部再把新的 `key-value` 键值对添加上去；如果哈希表中没有这个 `key` 值，那我们就直接把它添加到链表的末尾。然后，如果添加完之后，哈希表中的元素个数超出了容量限制，那就把链表头部的那个元素删除掉。



代码实现参考：

- [https://leetcode.com/problems/lru-cache/discuss/45926/Python-Dict-%2B-Double-LinkedList](https://leetcode.com/problems/lru-cache/discuss/45926/Python-Dict-%2B-Double-LinkedList)



